{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `This notebook generates a dictionary containing word name, start time, and end time for each word spoken in the indicated small clip of the original video and store the dictionary as \"script.txt\". To run this file, include a video file (rename it into \"clip.mp4\") under the same folder that this notebook resides and specify the start and end time of the target clip in the second block.`\n",
    "\n",
    "- intermediate files: audio_1.mp3, audio_16.mp3\n",
    "- output file: script.txt\n",
    "\n",
    "Last updated on August 3rd, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC\n",
    "from datasets import load_dataset\n",
    "import librosa\n",
    "import datasets\n",
    "import torch\n",
    "from IPython.display import Audio\n",
    "import moviepy.editor as mp\n",
    "import os\n",
    "import sox\n",
    "\n",
    "# import model, feature extractor, tokenizer\n",
    "model = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\",sampling_rate=16000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`process the audio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the audio in mp3 format from the clip\n",
    "clip = mp.VideoFileClip(\"clip.mp4\")\n",
    "start=285\n",
    "end=295\n",
    "# end = clip.duration\n",
    "\n",
    "# Save the paths for later\n",
    "clip_paths = []\n",
    "\n",
    "#try a small demo\n",
    "sub_clip=clip.subclip(start,end)\n",
    "sub_clip.audio.write_audiofile(\"audio_1.mp3\")\n",
    "clip_paths.append(\"audio_1.mp3\")\n",
    "\n",
    "#desample\n",
    "os.system('sox audio_1.mp3 -r 16000 audio_16.mp3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Actual output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the audio with the librosa library\n",
    "input_audio, sr = librosa.load(\"audio_16.mp3\", sr=16000)\n",
    "\n",
    "# forward sample through model to get greedily predicted transcription ids\n",
    "input_values = feature_extractor(input_audio, return_tensors=\"pt\").input_values\n",
    "logits = model(input_values).logits[0]\n",
    "pred_ids = torch.argmax(logits, axis=-1)\n",
    "\n",
    "# retrieve word stamps (analogous commands for `output_char_offsets`)\n",
    "outputs = tokenizer.decode(pred_ids, output_word_offsets=True)\n",
    "# compute `time_offset` in seconds as product of downsampling ratio and sampling_rate\n",
    "time_offset = model.config.inputs_to_logits_ratio / feature_extractor.sampling_rate\n",
    "\n",
    "word_offsets = [\n",
    "    {\n",
    "        \"word\": d[\"word\"],\n",
    "        \"start_time\": round(d[\"start_offset\"] * time_offset, 2),\n",
    "        \"end_time\": round(d[\"end_offset\"] * time_offset, 2),\n",
    "    }\n",
    "    for d in outputs.word_offsets\n",
    "]\n",
    "# compare word offsets with audio `common_voice_en_100038.mp3` online on the dataset viewer:\n",
    "# https://huggingface.co/datasets/common_voice/viewer/en/train\n",
    "\n",
    "#word_offsets is a list of dictionary\n",
    "word_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #find the time segmentation slot\n",
    "# timeSegList=[]\n",
    "# #find the place where to stop\n",
    "# for i in range(len(word_offsets)):\n",
    "#     if word_offsets[i]['word']==\"WAS\" or word_offsets[i]['word']==\"IS\":\n",
    "#         if word_offsets[i+1]['word']=='IT' and word_offsets[i+2]['word']=='A':\n",
    "#             timeSegList.append(word_offsets[i]['word'])\n",
    "\n",
    "with open('script.txt', 'w') as f:\n",
    "    for item in word_offsets:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e4e1b29a8f3351e0554dd3a0af00c8fcb68193190a462336a502cdea2c36c18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ve')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

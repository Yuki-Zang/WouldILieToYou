{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4476b9db-6f7b-4437-94f3-520e3e4cbc10",
   "metadata": {},
   "source": [
    "## This notebook includes:\n",
    "\n",
    "* Creating a Bidirectional LSTM based model (results reported in Table IV and V of the paper)\n",
    "* Running the model on multimodal ((audio, text, visual) data for classification for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b76cbd1-2b85-4146-bb2c-e17fc67a39eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:31.112832Z",
     "iopub.status.busy": "2023-04-11T19:09:31.112377Z",
     "iopub.status.idle": "2023-04-11T19:09:35.089230Z",
     "shell.execute_reply": "2023-04-11T19:09:35.087894Z",
     "shell.execute_reply.started": "2023-04-11T19:09:31.112739Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#for PCA\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05da3c8-f4ca-40b1-9c74-096ea29acd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:35.092586Z",
     "iopub.status.busy": "2023-04-11T19:09:35.091776Z",
     "iopub.status.idle": "2023-04-11T19:09:38.313449Z",
     "shell.execute_reply": "2023-04-11T19:09:38.312799Z",
     "shell.execute_reply.started": "2023-04-11T19:09:35.092544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_9481</th>\n",
       "      <th>feature_9482</th>\n",
       "      <th>feature_9483</th>\n",
       "      <th>feature_9484</th>\n",
       "      <th>feature_9485</th>\n",
       "      <th>feature_9486</th>\n",
       "      <th>feature_9487</th>\n",
       "      <th>feature_9488</th>\n",
       "      <th>feature_9489</th>\n",
       "      <th>feature_9490</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01e01-1</td>\n",
       "      <td>Dom Joly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>-0.075024</td>\n",
       "      <td>-0.035568</td>\n",
       "      <td>-0.017763</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>-0.089801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018490338698029518</td>\n",
       "      <td>0.08476332575082779</td>\n",
       "      <td>-0.11359433084726334</td>\n",
       "      <td>0.3834567070007324</td>\n",
       "      <td>0.2739666700363159</td>\n",
       "      <td>0.1074366569519043</td>\n",
       "      <td>0.46812331676483154</td>\n",
       "      <td>0.1457563191652298</td>\n",
       "      <td>0.12616167962551117</td>\n",
       "      <td>-0.029206672683358192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s01e01-2</td>\n",
       "      <td>Duncan Bannatyne</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.088031</td>\n",
       "      <td>-0.045368</td>\n",
       "      <td>-0.046058</td>\n",
       "      <td>0.067916</td>\n",
       "      <td>0.189048</td>\n",
       "      <td>-0.013381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09824812412261963</td>\n",
       "      <td>0.16229026019573212</td>\n",
       "      <td>0.16081875562667847</td>\n",
       "      <td>0.32505500316619873</td>\n",
       "      <td>0.34945249557495117</td>\n",
       "      <td>-0.09781775623559952</td>\n",
       "      <td>0.23907776176929474</td>\n",
       "      <td>0.09811551123857498</td>\n",
       "      <td>0.052620500326156616</td>\n",
       "      <td>-0.08417987823486328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s01e01-3</td>\n",
       "      <td>Natalie Cassidy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>-0.008859</td>\n",
       "      <td>-0.113927</td>\n",
       "      <td>-0.007059</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.131093</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08289637416601181</td>\n",
       "      <td>0.21903474628925323</td>\n",
       "      <td>-0.07876124978065491</td>\n",
       "      <td>0.1481068730354309</td>\n",
       "      <td>0.18827761709690094</td>\n",
       "      <td>-0.14032037556171417</td>\n",
       "      <td>0.05450335144996643</td>\n",
       "      <td>0.13083963096141815</td>\n",
       "      <td>0.04116374999284744</td>\n",
       "      <td>-0.15561625361442566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s01e01-6</td>\n",
       "      <td>Dom Joly</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031647</td>\n",
       "      <td>0.064775</td>\n",
       "      <td>-0.043998</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.141178</td>\n",
       "      <td>-0.005597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09112167358398438</td>\n",
       "      <td>0.03759665787220001</td>\n",
       "      <td>0.19848668575286865</td>\n",
       "      <td>0.28718501329421997</td>\n",
       "      <td>-0.0735669955611229</td>\n",
       "      <td>0.061839908361434937</td>\n",
       "      <td>0.12194333225488663</td>\n",
       "      <td>0.263722687959671</td>\n",
       "      <td>-0.13163550198078156</td>\n",
       "      <td>-0.2921786606311798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s01e01-7</td>\n",
       "      <td>Frankie Boyle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.159030</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>-0.043233</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>0.147742</td>\n",
       "      <td>-0.038791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37825965881347656</td>\n",
       "      <td>0.2722756564617157</td>\n",
       "      <td>-0.14988566935062408</td>\n",
       "      <td>0.24854867160320282</td>\n",
       "      <td>0.17865000665187836</td>\n",
       "      <td>-0.2249843329191208</td>\n",
       "      <td>-0.3870030343532562</td>\n",
       "      <td>0.11379333585500717</td>\n",
       "      <td>0.11868665367364883</td>\n",
       "      <td>-0.4633199870586395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>s14e08-3</td>\n",
       "      <td>Roisin Conaty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040339</td>\n",
       "      <td>-0.011892</td>\n",
       "      <td>-0.050313</td>\n",
       "      <td>-0.040630</td>\n",
       "      <td>0.020426</td>\n",
       "      <td>0.106055</td>\n",
       "      <td>0.018815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08795725554227829</td>\n",
       "      <td>0.0237351655960083</td>\n",
       "      <td>-0.032572004944086075</td>\n",
       "      <td>0.15692858397960663</td>\n",
       "      <td>0.10141167044639587</td>\n",
       "      <td>-0.17155317962169647</td>\n",
       "      <td>0.2923780679702759</td>\n",
       "      <td>0.26045724749565125</td>\n",
       "      <td>-0.09290068596601486</td>\n",
       "      <td>-0.22868959605693817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>s14e08-4</td>\n",
       "      <td>Roman Kemp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.028110</td>\n",
       "      <td>0.169771</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.031299</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.127590</td>\n",
       "      <td>-0.002619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12971431016921997</td>\n",
       "      <td>0.037154700607061386</td>\n",
       "      <td>0.026378804817795753</td>\n",
       "      <td>0.23197659850120544</td>\n",
       "      <td>0.1548031121492386</td>\n",
       "      <td>-0.14210765063762665</td>\n",
       "      <td>0.3862755596637726</td>\n",
       "      <td>0.3016236424446106</td>\n",
       "      <td>0.015786344185471535</td>\n",
       "      <td>-0.2246006727218628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>s14e09-1</td>\n",
       "      <td>Alex Jones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027228</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.041564</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.119052</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17405150830745697</td>\n",
       "      <td>0.12252228707075119</td>\n",
       "      <td>0.1441657841205597</td>\n",
       "      <td>0.1589970886707306</td>\n",
       "      <td>0.15254013240337372</td>\n",
       "      <td>-0.07880286127328873</td>\n",
       "      <td>0.3323584198951721</td>\n",
       "      <td>0.34674471616744995</td>\n",
       "      <td>-0.025951789692044258</td>\n",
       "      <td>-0.1538473516702652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>s14e09-3</td>\n",
       "      <td>Martin Lewis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007263</td>\n",
       "      <td>0.050732</td>\n",
       "      <td>-0.050518</td>\n",
       "      <td>-0.090673</td>\n",
       "      <td>0.044292</td>\n",
       "      <td>0.085449</td>\n",
       "      <td>-0.058811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1738501787185669</td>\n",
       "      <td>0.09341058135032654</td>\n",
       "      <td>0.12290232628583908</td>\n",
       "      <td>-0.006683960556983948</td>\n",
       "      <td>0.08657991141080856</td>\n",
       "      <td>-0.01124399434775114</td>\n",
       "      <td>0.519538402557373</td>\n",
       "      <td>0.24855166673660278</td>\n",
       "      <td>-0.03214416280388832</td>\n",
       "      <td>-0.2781267464160919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>s14e09-5</td>\n",
       "      <td>Johnny Vegas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029845</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.071973</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.139424</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041211798787117004</td>\n",
       "      <td>0.07078119367361069</td>\n",
       "      <td>0.27036601305007935</td>\n",
       "      <td>0.10536470264196396</td>\n",
       "      <td>0.018079612404108047</td>\n",
       "      <td>-0.08423899114131927</td>\n",
       "      <td>0.4934275150299072</td>\n",
       "      <td>0.3888877034187317</td>\n",
       "      <td>0.2644529938697815</td>\n",
       "      <td>-0.060886092483997345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows Ã— 6999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id           speaker  label  feature_1  feature_2  feature_3  \\\n",
       "0    s01e01-1          Dom Joly    1.0   0.005139   0.029560  -0.075024   \n",
       "1    s01e01-2  Duncan Bannatyne    1.0   0.007152   0.088031  -0.045368   \n",
       "2    s01e01-3   Natalie Cassidy    0.0   0.048681  -0.008859  -0.113927   \n",
       "3    s01e01-6          Dom Joly    0.0   0.031647   0.064775  -0.043998   \n",
       "4    s01e01-7     Frankie Boyle    1.0   0.003951   0.159030  -0.007606   \n",
       "..        ...               ...    ...        ...        ...        ...   \n",
       "351  s14e08-3     Roisin Conaty    1.0   0.040339  -0.011892  -0.050313   \n",
       "352  s14e08-4        Roman Kemp    1.0  -0.028110   0.169771   0.022322   \n",
       "353  s14e09-1        Alex Jones    1.0   0.027228  -0.017874  -0.041564   \n",
       "354  s14e09-3      Martin Lewis    1.0  -0.007263   0.050732  -0.050518   \n",
       "355  s14e09-5      Johnny Vegas    0.0   0.029845   0.110750  -0.001955   \n",
       "\n",
       "     feature_4  feature_5  feature_6  feature_7  ...          feature_9481  \\\n",
       "0    -0.035568  -0.017763   0.110714  -0.089801  ...  0.018490338698029518   \n",
       "1    -0.046058   0.067916   0.189048  -0.013381  ...  -0.09824812412261963   \n",
       "2    -0.007059   0.075472   0.131093   0.009876  ...   0.08289637416601181   \n",
       "3    -0.019308   0.028442   0.141178  -0.005597  ...   0.09112167358398438   \n",
       "4    -0.043233   0.070793   0.147742  -0.038791  ...   0.37825965881347656   \n",
       "..         ...        ...        ...        ...  ...                   ...   \n",
       "351  -0.040630   0.020426   0.106055   0.018815  ...   0.08795725554227829   \n",
       "352  -0.031299   0.017207   0.127590  -0.002619  ...   0.12971431016921997   \n",
       "353  -0.041545   0.013167   0.119052   0.008405  ...   0.17405150830745697   \n",
       "354  -0.090673   0.044292   0.085449  -0.058811  ...    0.1738501787185669   \n",
       "355  -0.071973   0.066997   0.139424   0.009984  ...  0.041211798787117004   \n",
       "\n",
       "             feature_9482           feature_9483           feature_9484  \\\n",
       "0     0.08476332575082779   -0.11359433084726334     0.3834567070007324   \n",
       "1     0.16229026019573212    0.16081875562667847    0.32505500316619873   \n",
       "2     0.21903474628925323   -0.07876124978065491     0.1481068730354309   \n",
       "3     0.03759665787220001    0.19848668575286865    0.28718501329421997   \n",
       "4      0.2722756564617157   -0.14988566935062408    0.24854867160320282   \n",
       "..                    ...                    ...                    ...   \n",
       "351    0.0237351655960083  -0.032572004944086075    0.15692858397960663   \n",
       "352  0.037154700607061386   0.026378804817795753    0.23197659850120544   \n",
       "353   0.12252228707075119     0.1441657841205597     0.1589970886707306   \n",
       "354   0.09341058135032654    0.12290232628583908  -0.006683960556983948   \n",
       "355   0.07078119367361069    0.27036601305007935    0.10536470264196396   \n",
       "\n",
       "             feature_9485          feature_9486         feature_9487  \\\n",
       "0      0.2739666700363159    0.1074366569519043  0.46812331676483154   \n",
       "1     0.34945249557495117  -0.09781775623559952  0.23907776176929474   \n",
       "2     0.18827761709690094  -0.14032037556171417  0.05450335144996643   \n",
       "3     -0.0735669955611229  0.061839908361434937  0.12194333225488663   \n",
       "4     0.17865000665187836   -0.2249843329191208  -0.3870030343532562   \n",
       "..                    ...                   ...                  ...   \n",
       "351   0.10141167044639587  -0.17155317962169647   0.2923780679702759   \n",
       "352    0.1548031121492386  -0.14210765063762665   0.3862755596637726   \n",
       "353   0.15254013240337372  -0.07880286127328873   0.3323584198951721   \n",
       "354   0.08657991141080856  -0.01124399434775114    0.519538402557373   \n",
       "355  0.018079612404108047  -0.08423899114131927   0.4934275150299072   \n",
       "\n",
       "            feature_9488           feature_9489           feature_9490  \n",
       "0     0.1457563191652298    0.12616167962551117  -0.029206672683358192  \n",
       "1    0.09811551123857498   0.052620500326156616   -0.08417987823486328  \n",
       "2    0.13083963096141815    0.04116374999284744   -0.15561625361442566  \n",
       "3      0.263722687959671   -0.13163550198078156    -0.2921786606311798  \n",
       "4    0.11379333585500717    0.11868665367364883    -0.4633199870586395  \n",
       "..                   ...                    ...                    ...  \n",
       "351  0.26045724749565125   -0.09290068596601486   -0.22868959605693817  \n",
       "352   0.3016236424446106   0.015786344185471535    -0.2246006727218628  \n",
       "353  0.34674471616744995  -0.025951789692044258    -0.1538473516702652  \n",
       "354  0.24855166673660278   -0.03214416280388832    -0.2781267464160919  \n",
       "355   0.3888877034187317     0.2644529938697815  -0.060886092483997345  \n",
       "\n",
       "[349 rows x 6999 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read lexical-acoustic data\n",
    "al_data = np.load(\"regularOnly.npy\", allow_pickle = True)\n",
    "al_data = np.delete(al_data, 3889, axis=1)\n",
    "al_data = np.delete(al_data, 3894, axis=1)\n",
    "#print(al_data.shape)\n",
    "\n",
    "#getting columns names ready for merging\n",
    "feature_columns = ['feature_{}'.format(i) for i in range (2623, 9491)]\n",
    "other_columns = ['id', 'speaker', 'label']\n",
    "feature_cols = other_columns + feature_columns\n",
    "\n",
    "#get final dataframe containing verbal (acoustic-prosodic and linguistic data)\n",
    "al_data = pd.DataFrame(al_data, columns = feature_cols)\n",
    "al_data\n",
    "\n",
    "# get visual data\n",
    "vis_data = pd.read_csv('/notebooks/visual_features/data_OpenFace_1.csv', index_col = [0])\n",
    "\n",
    "# merge acoustic-prosodic and visual data\n",
    "final_dataset = pd.merge(vis_data, al_data.drop(columns =['speaker', 'label']), how = 'right', on = 'id', sort = True)\n",
    "final_dataset = final_dataset.rename(columns = {\"speaker_x\":\"speaker\", \"label_x\": \"label\"})\n",
    "final_dataset = final_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54b287b-0129-43ea-b8b7-6afeb1a978e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:38.315441Z",
     "iopub.status.busy": "2023-04-11T19:09:38.314486Z",
     "iopub.status.idle": "2023-04-11T19:09:38.322156Z",
     "shell.execute_reply": "2023-04-11T19:09:38.321310Z",
     "shell.execute_reply.started": "2023-04-11T19:09:38.315398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: function to save the test set for summary statistics\n",
    "def test(testIndex, test_Y, test_X, r):\n",
    "    a = np.expand_dims(np.array(testIndex), axis = 1) # index\n",
    "    b = np.expand_dims(np.array(test_Y), axis = 1)  # test labels\n",
    "    \n",
    "    final = np.concatenate((a, test_X), axis = 1)\n",
    "    final = np.concatenate((final, b), axis = 1)\n",
    "\n",
    "    np.save('/notebooks/data_{}.npy'.format(r), final)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e90bc55-2464-4fe8-abb7-1eccfe01a95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:38.325026Z",
     "iopub.status.busy": "2023-04-11T19:09:38.324177Z",
     "iopub.status.idle": "2023-04-11T19:09:40.392702Z",
     "shell.execute_reply": "2023-04-11T19:09:40.391592Z",
     "shell.execute_reply.started": "2023-04-11T19:09:38.324998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: 0.9727965360097709\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_by_speaker(data, test_size=0.2, pca=False, numPC=300):\n",
    "    '''\n",
    "    parameters:\n",
    "    data: type to be decided, the dataset that we will train the model on\n",
    "    test_size: the percentage of test data, by default 0.2\n",
    "    pca: Bool. if to conduct PCA on the dataset, by default False\n",
    "    numPca: number of principal components, by default 50\n",
    "    \n",
    "    return:\n",
    "    train_x:\n",
    "    train_y:\n",
    "    test_x:\n",
    "    test_y:\n",
    "    '''\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    #get the speaker name column\n",
    "    name = data[:,1]\n",
    "    nameList = []\n",
    "    nameIndexDic = {}\n",
    "    for i in range(name.shape[0]):\n",
    "        try: \n",
    "            nameIndexDic[name[i]].append(i)\n",
    "        except:\n",
    "            nameList.append(name[i])\n",
    "            nameIndexDic[name[i]] = [i]\n",
    "    nameList = np.array(nameList)\n",
    "    np.random.shuffle(nameList)\n",
    "\n",
    "\n",
    "    numOfVector = round(len(nameList)*test_size)\n",
    "    \n",
    "    testIndex = []\n",
    "    trainIndex = []\n",
    "    \n",
    "    #create index list for train and test \n",
    "    for j in range(len(nameList)):\n",
    "        \n",
    "        #first test dataset\n",
    "        if j < numOfVector:\n",
    "            testIndex = testIndex + nameIndexDic[nameList[j]]\n",
    "        \n",
    "        #rest goes to train set\n",
    "        else: \n",
    "            trainIndex = trainIndex + nameIndexDic[nameList[j]]\n",
    "    \n",
    "    \n",
    "    data = data[:,2:].astype(float)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[:, 1:])\n",
    "    \n",
    "    if pca == True:\n",
    "        pcaModel = PCA(numPC) \n",
    "        pcaData = pcaModel.fit_transform(scaled_data)\n",
    "        \n",
    "        print('Explained variance:', np.sum(pcaModel.explained_variance_ratio_))\n",
    "    \n",
    "        scaled_data = pcaData\n",
    "    \n",
    "    #split data\n",
    "    test = scaled_data[testIndex]\n",
    "    train = scaled_data[trainIndex]\n",
    "\n",
    "    #split labels\n",
    "    test_l = data[testIndex]\n",
    "    train_l = data[trainIndex]\n",
    "    \n",
    "    \n",
    "    test_x = test.astype(float)\n",
    "    test_y = test_l[:,0].astype(int)\n",
    "    \n",
    "    train_x = train.astype(float)\n",
    "    train_y = train_l[:,0].astype(int)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, nameIndexDic, testIndex\n",
    "\n",
    "train_X, train_Y, test_X, test_Y, dic, testIndex = train_test_split_by_speaker(df, pca=True,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6ee105-5906-473f-9719-17ca123119ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:40.394679Z",
     "iopub.status.busy": "2023-04-11T19:09:40.394403Z",
     "iopub.status.idle": "2023-04-11T19:09:40.407151Z",
     "shell.execute_reply": "2023-04-11T19:09:40.406155Z",
     "shell.execute_reply.started": "2023-04-11T19:09:40.394639Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model_n_times(n=10):\n",
    "    #create the final statistics array\n",
    "    final = []\n",
    "    \n",
    "    #initialize the model\n",
    "    max_features = 1000 # ALL THE FEATURES\n",
    "    maxlen = 100 \n",
    "\n",
    "    # Input for variable-length sequences of integers\n",
    "    inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "    \n",
    "    # Embed each integer in a 128-dimensional vector\n",
    "    x = layers.Embedding(max_features, 128)(inputs)\n",
    "    # Add 1 bidirectional LSTMs\n",
    "    x = layers.Bidirectional(layers.LSTM(256))(x)\n",
    "    \n",
    "    # Add a classifier\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "    \n",
    "    \n",
    "    for r in range(n):\n",
    "        print(r)\n",
    "        train_X, train_Y, test_X, test_Y, dic, testIndex = train_test_split_by_speaker(df, test_size=0.2, pca=True, numPC=300)\n",
    "        \n",
    "        test(testIndex, test_Y, test_X, r)\n",
    "        \n",
    "        # test if there is empty result\n",
    "        na = np.isnan(train_X)\n",
    "\n",
    "        for i in range(na.shape[0]):\n",
    "            for j in range(na.shape[1]):\n",
    "                if bool(na[i,j])==True:\n",
    "                    print(i,j)         \n",
    "\n",
    "        train_X = keras.preprocessing.sequence.pad_sequences(train_X, maxlen=maxlen)\n",
    "        test_X = keras.preprocessing.sequence.pad_sequences(test_X, maxlen=maxlen)\n",
    "    \n",
    "        model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", keras.metrics.Precision(),keras.metrics.Recall(),keras.metrics.AUC()])\n",
    "        result = model.fit(train_X, train_Y, batch_size=32, epochs=100, validation_data=(test_X, test_Y))\n",
    "        \n",
    "        #tf.saved_model.save(model, '/notebooks/best_model')\n",
    "        model.save('/notebooks/best_model/model_{}.keras'.format(r))\n",
    "        \n",
    "        #from: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model \n",
    "        y_pred = model.predict(test_X, batch_size=32, verbose=1)\n",
    "        y_pred_bool = np.round(y_pred)\n",
    "        print(classification_report(test_Y, y_pred_bool))\n",
    "        \n",
    "        #get confusion matrix\n",
    "        confusion = confusion_matrix(test_Y, y_pred_bool)\n",
    "        #print(confusion)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=[1, 0])\n",
    "        disp.plot()\n",
    "        \n",
    "        #plot statistics\n",
    "        #pd.DataFrame(result.history).plot(figsize=(8,5))\n",
    "        #plt.show()\n",
    "        \n",
    "        \n",
    "        statistics = []\n",
    "        index = 0\n",
    "        for data in result.history.values():\n",
    "            if index >= 6:\n",
    "                statistics.append(data[-1]) \n",
    "            index += 1\n",
    "        statistics.append(2*statistics[1]*statistics[2]/(statistics[1]+statistics[2]))\n",
    "        final.append(statistics)\n",
    "        \n",
    "    final = pd.DataFrame(final, columns=[\"accuracy\", \"precision\", \"recall\", \"auc\", \"f1\"])\n",
    "    \n",
    "    # final statistic array should look like\n",
    "    # [accuracy, precision, recall, auc, f1]\n",
    "    return final.quantile([0.25, 0.5, 0.75]), final.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e7fd5-2ea3-480f-a017-80c2d546e931",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-11T19:09:40.408877Z",
     "iopub.status.busy": "2023-04-11T19:09:40.408296Z",
     "iopub.status.idle": "2023-04-11T19:16:10.640009Z",
     "shell.execute_reply": "2023-04-11T19:16:10.639208Z",
     "shell.execute_reply.started": "2023-04-11T19:09:40.408852Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# run model 10 times\n",
    "print(\"\\n\\n\\n\\n\\n\", run_model_n_times(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
